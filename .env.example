# =============================================================================
# LLM Gateway Configuration
# =============================================================================
# Copy this file to .env and update the values

# -----------------------------------------------------------------------------
# Environment
# -----------------------------------------------------------------------------
ENVIRONMENT=development  # development, staging, production, test

# -----------------------------------------------------------------------------
# Database Configuration (PostgreSQL)
# -----------------------------------------------------------------------------
SQL_USER=llm_gateway
SQL_PASSWD=llm_gateway_secret
SQL_NAME=llm_gateway
SQL_HOST=localhost
SQL_PORT=5432
DB_POOL_SIZE=5
DB_MAX_OVERFLOW=10

# -----------------------------------------------------------------------------
# Authentication
# -----------------------------------------------------------------------------
# URL for external auth verification (not used in local mode)
AUTH_VERIFY_URL=http://localhost:8000/api/v1/token/verify/

# Secret keys (min 32 characters each)
DJANGO_SECRET_KEY=your-django-secret-key-min-32-characters-here
JWT_SECRET=your-jwt-secret-key-min-32-characters-here

# JWT Configuration
JWT_ALGORITHM=HS256  # HS256 or RS256
# JWT_JWKS_URL=       # Required for RS256
# JWT_AUDIENCE=       # Optional: expected audience
# JWT_ISSUER=         # Optional: expected issuer

# Static JWT token for testing (optional)
# JWT_TOKEN=your_test_jwt_token

# -----------------------------------------------------------------------------
# CORS
# -----------------------------------------------------------------------------
CORS_ORIGINS=http://localhost:3000,http://localhost:8080

# -----------------------------------------------------------------------------
# LLM Providers
# -----------------------------------------------------------------------------
# OpenAI (or OpenAI-compatible like LM Studio, Ollama)
OPENAI_API_KEY=sk-local  # For local models, any non-empty value works
OPENAI_BASE_URL=http://localhost:1234/v1  # LM Studio / Ollama endpoint
# OPENAI_ORG_ID=                           # Optional: OpenAI organization ID

# Anthropic (optional)
# ANTHROPIC_API_KEY=sk-ant-...
# ANTHROPIC_BASE_URL=                      # Optional: custom endpoint

# LLM Request Configuration
LLM_TIMEOUT=120           # Request timeout in seconds
LLM_MAX_RETRIES=3         # Max retries for failed requests
LLM_DEFAULT_MODEL=bartowski/Codestral-22B-v0.1-GGUF  # Default model name

# -----------------------------------------------------------------------------
# Redis (optional - used for caching and rate limiting)
# -----------------------------------------------------------------------------
# REDIS_URL=redis://localhost:6379/0
# REDIS_TTL=3600  # Default TTL in seconds

# -----------------------------------------------------------------------------
# Rate Limiting
# -----------------------------------------------------------------------------
RATE_LIMIT_ENABLED=false   # Disable for local development
RATE_LIMIT_REQUESTS=100    # Requests per window
RATE_LIMIT_WINDOW=60       # Window in seconds

# -----------------------------------------------------------------------------
# Application
# -----------------------------------------------------------------------------
DEBUG=true
LOG_LEVEL=DEBUG  # DEBUG, INFO, WARNING, ERROR, CRITICAL

# Content limits
MAX_CONTENT_LENGTH=100000     # Max message length in chars
MAX_MESSAGES_PER_DIALOG=1000  # Max messages per dialog

# Token limits for users
# DEFAULT_TOKEN_LIMIT=         # Default limit (empty = unlimited)
INITIAL_TOKEN_BALANCE=1000000  # Initial balance for new users
